Create a Python Flask web application that functions as a chatbot interface, closely mimicking the layout and style shown in the provided image (image_149c08.png).

Core Requirements:

Frontend Interface (HTML, CSS, JavaScript):

Replicate the three-section layout:
Left Sidebar: Placeholder for chat history (actual saving/loading can be added later). Include a "New Chat" button at the top and a "Clear conversations" button/link at the bottom. Initially, it can just show static example conversation titles like in the image.
Main Chat Area: Display the conversation between the user and the chatbot. Include a "Welcome" message similar to the image. Ensure messages scroll correctly.
Bottom Input Area:
Include an input text field for the user to type their message.
Include exactly six preset buttons below the input field to select specific AI models. Based on the image, label these buttons: "Gemini 1.5 Pro", "Claude 3 Sonnet" (or best guess from image), "Mistral Large" (or best guess), "GPT-4o", "Sonar Large" (or best guess), "Free Gemini". Clicking a button should select that model for the next message sent. Indicate the currently selected model visually if possible.
Include a Send button (or handle submission via Enter key).
Styling: Use a dark theme with teal/green accents, similar to the image. Make it clean and modern.
Backend (Python Flask):

Set up a basic Flask server.
Create an endpoint (e.g., /chat) that accepts POST requests containing the user's message and the selected OpenRouter model ID (corresponding to the preset buttons).
Crucially, integrate with the OpenRouter API (https://openrouter.ai/api/v1/chat/completions).
Use an environment variable (OPENROUTER_API_KEY) stored in Replit Secrets for the API key.
When calling the OpenRouter API, set the stream: true parameter.
The backend endpoint must handle the Server-Sent Events (SSE) stream returned by OpenRouter.
Stream the response directly to the frontend: Do not buffer the entire response on the backend. As chunks of the message arrive via SSE from OpenRouter, they should be immediately forwarded to the frontend using SSE.
OpenRouter Integration Details:

The application needs to know the specific OpenRouter model IDs corresponding to the six preset buttons (e.g., openai/gpt-4o, google/gemini-1.5-pro-latest, etc. - You might need to look these up on OpenRouter). Map the button labels to the correct IDs in the backend logic.
While the prompt asks for all models, for this initial build, focus on making the six preset buttons functional with streaming. The backend should be structured to potentially handle any model ID passed from the frontend in the future.
Streaming (Most Important - Initial Build):

The primary goal for this first version is implementing the end-to-end streaming.
Frontend JavaScript: Must be able to initiate a request to the backend /chat endpoint and handle the incoming SSE stream, appending the received text chunks to the chat display in real-time.
File Structure Suggestion:

main.py (Flask app)
templates/index.html (Frontend HTML)
static/style.css (CSS styling)
static/script.js (Frontend JavaScript for interaction and SSE handling)
requirements.txt (Python dependencies, e.g., Flask, requests)
Instructions for AI: Focus first on setting up the basic Flask structure, the HTML layout, and the core SSE streaming functionality between the frontend, backend, and OpenRouter. Use placeholder elements where necessary (like the chat history list). Ensure the OpenRouter API call correctly uses stream: true and the Flask backend relays the SSE stream.