Fix two issues in the chatbot application:

AI messages are truncated before finishing.
Metadata (Model used, Tokens) is not displayed below AI messages immediately after they are generated.
Apply the following specific changes to app.py and static/js/script.js to resolve these problems by refactoring how the stream is processed, how metadata is handled, and when database operations occur.

1. Modify app.py:

Replace the entire generate() function (defined inside the chat endpoint) with the following corrected version. This version collects content and metadata during the stream, performs database operations only after the stream loop finishes, and sends a final metadata event via SSE before the done event.
Python

# === CODE TO REPLACE THE generate() FUNCTION IN app.py ===
def generate():
    # Buffer to collect the assistant's response text
    assistant_response_content = [] 
    # Variables to store metadata found during stream
    final_prompt_tokens = None
    final_completion_tokens = None
    final_model_id_used = None
    assistant_message_id = None # To store the ID after saving

    try:
        response = requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers, # Assumes headers is defined in the outer scope (chat endpoint)
            json=payload,    # Assumes payload is defined in the outer scope (chat endpoint)
            stream=True
        )

        if response.status_code != 200:
            logger.error(f"OpenRouter API error: {response.status_code} - {response.text}")
            yield f"data: {json.dumps({'type': 'error', 'error': f'API Error: {response.status_code}'})}\n\n"
            return

        # Process the streaming response
        for line in response.iter_lines():
            if line:
                if line.strip() == b'':
                    continue # Skip keep-alive lines
                
                line_text = line.decode('utf-8')
                
                if line_text.startswith('data: '):
                    sse_data = line_text[6:].strip() # Remove prefix and potential trailing whitespace
                    
                    if sse_data == '[DONE]':
                        # We will handle completion after the loop finishes fully processing all data
                        continue 
                        
                    try:
                        # Ensure we are parsing valid JSON data
                        if not sse_data: 
                            continue
                        json_data = json.loads(sse_data)
                        
                        # --- Extract Content ---
                        content_chunk = None
                        if 'choices' in json_data and len(json_data['choices']) > 0:
                            choice = json_data['choices'][0]
                            # Check for delta and content, ensuring it's not null
                            if 'delta' in choice and choice['delta'].get('content') is not None:
                                content_chunk = choice['delta']['content']
                            # Add other formats if necessary (e.g., 'text') - check your specific models
                        
                        if content_chunk:
                            assistant_response_content.append(content_chunk)
                            # Yield content chunk to the client
                            # Ensure conversation_id is available from outer scope
                            yield f"data: {json.dumps({'type': 'content', 'content': content_chunk, 'conversation_id': conversation_id})}\n\n"
                            # logger.debug(f"Streamed content chunk: {content_chunk[:20]}...") # Optional: reduce logging verbosity

                        # --- Extract Usage/Model (often in final non-content chunk) ---
                        # Check if 'usage' exists and has content
                        if 'usage' in json_data and json_data['usage']: 
                            usage = json_data['usage']
                            final_prompt_tokens = usage.get('prompt_tokens')
                            final_completion_tokens = usage.get('completion_tokens')
                            logger.debug(f"Found usage data: P:{final_prompt_tokens} C:{final_completion_tokens}")
                        
                        # Check if 'model' exists and has content
                        if 'model' in json_data and json_data['model']:
                            # Capture the specific model string returned by the API response
                            final_model_id_used = json_data.get('model')
                            logger.debug(f"Found model used: {final_model_id_used}")

                    except json.JSONDecodeError as e:
                        logger.error(f"JSON decode error: {e} on line content: {sse_data}")
                        yield f"data: {json.dumps({'type': 'error', 'error': 'JSON parsing error'})}\n\n"
                        return # Stop processing on parsing error

        # --- Stream processing finished ---
        
        # Combine the full response
        full_response_text = ''.join(assistant_response_content)
        
        # Save the complete assistant message to the database NOW if content exists
        if full_response_text: 
            try:
                from models import Message # Ensure import is available
                # Ensure conversation_id and model_id (requested) are available from outer scope
                assistant_db_message = Message(
                    conversation_id=conversation_id,
                    role='assistant',
                    content=full_response_text,
                    model=model_id, # Original requested model shorthand/ID from outer scope
                    model_id_used=final_model_id_used, # Actual model used from API
                    prompt_tokens=final_prompt_tokens,
                    completion_tokens=final_completion_tokens,
                    rating=None # Default rating
                )
                db.session.add(assistant_db_message)
                db.session.commit()
                assistant_message_id = assistant_db_message.id # Get the ID
                logger.info(f"Saved assistant message {assistant_message_id} with metadata.")

                # Save to memory system if enabled (ensure ENABLE_MEMORY_SYSTEM etc. are available)
                if ENABLE_MEMORY_SYSTEM:
                     try:
                         memory_user_id = str(current_user.id) if current_user and current_user.is_authenticated else f"anonymous_{conversation_id}"
                         save_message_with_memory(
                             session_id=str(conversation_id),
                             user_id=memory_user_id,
                             role='assistant',
                             content=full_response_text
                         )
                     except Exception as e:
                         logger.error(f"Error saving assistant message to memory: {e}")

                # Yield the final metadata to the client
                yield f"data: {json.dumps({'type': 'metadata', 'metadata': {'id': assistant_message_id, 'model_id_used': final_model_id_used, 'prompt_tokens': final_prompt_tokens, 'completion_tokens': final_completion_tokens}})}\n\n"

            except Exception as db_error:
                logger.exception("Error saving assistant message or metadata to DB")
                db.session.rollback()
                yield f"data: {json.dumps({'type': 'error', 'error': 'Error saving message to database'})}\n\n"
                # Still yield done even if DB save fails? Or return? Let's yield done for now.
        
        # Finally, signal completion (even if no text content was generated)
        # Ensure conversation_id is available
        yield f"data: {json.dumps({'type': 'done', 'done': True, 'conversation_id': conversation_id})}\n\n"
        logger.info("Stream generation complete.")

    except Exception as e:
        logger.exception("Error during stream generation")
        yield f"data: {json.dumps({'type': 'error', 'error': f'Stream Error: {str(e)}'})}\n\n"
# === END OF REPLACEMENT CODE FOR generate() ===
2. Modify static/js/script.js:

Update the streaming logic within the sendMessageToBackend function, specifically the processChunks inner function (or equivalent logic if you structured it differently), to correctly handle the new type field (content, metadata, done, error) sent by the refactored backend. Replace the relevant part of your stream processing loop with this logic:
JavaScript

// === CODE TO REPLACE/UPDATE STREAM PROCESSING LOGIC IN sendMessageToBackend ===
                // Ensure assistantMessageElement and messageContent are defined before this block

                // Function to process chunks
                function processChunks() {
                    return reader.read().then(({ done, value }) => {
                        if (done) {
                            console.log("Reader finished."); 
                            // Final history push should happen upon receiving the 'done' type message now
                            return;
                        }
                        
                        // Decode the chunk and add to buffer
                        buffer += decoder.decode(value, { stream: true });
                        
                        // Process each line in the buffer
                        // Use a robust way to split SSE messages (double newline)
                        const potentialMessages = buffer.split('\n\n');
                        buffer = potentialMessages.pop(); // Keep incomplete message in buffer

                        // Process each complete message
                        for (const message of potentialMessages) {
                            if (message.trim() === '') continue;
                            
                            if (message.startsWith('data: ')) {
                                const data = message.substring(6).trim(); // Remove 'data: ' and trim
                                
                                if (!data) continue; // Skip empty data lines

                                try {
                                    const parsedData = JSON.parse(data);
                                    
                                    // --- Handle different data types ---
                                    if (parsedData.type === 'error' || parsedData.error) {
                                        const errorMsg = parsedData.error || 'Unknown error occurred';
                                        messageContent.innerHTML = `<span class="error">Error: ${errorMsg}</span>`;
                                        console.error("Received error from backend:", errorMsg);
                                        // Optionally re-enable input/button here if desired
                                        // messageInput.disabled = false;
                                        // sendButton.disabled = false;
                                        return; // Stop processing on error
                                    
                                    } else if (parsedData.type === 'content') {
                                        // Append content
                                        if (parsedData.content) {
                                            responseText += parsedData.content;
                                            // Use your existing formatMessage function
                                            messageContent.innerHTML = formatMessage(responseText); 
                                            chatMessages.scrollTop = chatMessages.scrollHeight;
                                        }
                                        // Update conversation ID if it's the first message
                                        if (parsedData.conversation_id && !currentConversationId) {
                                            currentConversationId = parsedData.conversation_id;
                                            console.log(`Setting conversation ID: ${currentConversationId}`);
                                            // Store conversation ID on the message element if needed
                                            // assistantMessageElement.dataset.conversationId = currentConversationId; 
                                            // Optionally refresh conversation list
                                            // fetchConversations(); 
                                        }
                                    
                                    } else if (parsedData.type === 'metadata') {
                                        // Metadata received (usually after content stream ends)
                                        console.log("Received metadata:", parsedData.metadata);
                                        if (parsedData.metadata) {
                                            const meta = parsedData.metadata;
                                            
                                            // Set the definitive message ID on the element
                                            assistantMessageElement.dataset.messageId = meta.id;
                                            
                                            // Update/Create metadata display section
                                            const messageWrapper = assistantMessageElement.querySelector('.message-wrapper');
                                            if (messageWrapper) { // Check if wrapper exists
                                                let metadataContainer = messageWrapper.querySelector('.message-metadata');
                                                if (!metadataContainer) {
                                                    metadataContainer = document.createElement('div');
                                                    metadataContainer.className = 'message-metadata';
                                                    // Insert metadata before action buttons if they exist
                                                    const actionsContainer = messageWrapper.querySelector('.message-actions');
                                                    if (actionsContainer) {
                                                        messageWrapper.insertBefore(metadataContainer, actionsContainer);
                                                    } else {
                                                        // Append if actions aren't there (e.g., if they load later)
                                                        messageWrapper.appendChild(metadataContainer); 
                                                    }
                                                }
                                                
                                                // Format metadata text
                                                let metadataText = '';
                                                const modelName = meta.model_id_used ? formatModelName(meta.model_id_used) : 'N/A';
                                                metadataText += `Model: ${modelName}`;
                                                
                                                if (meta.prompt_tokens !== null && meta.completion_tokens !== null) {
                                                     metadataText += ` Â· Tokens: ${meta.prompt_tokens} prompt + ${meta.completion_tokens} completion`;
                                                }
                                                metadataContainer.textContent = metadataText;
                                            }

                                            // Update action buttons now that we have the final message ID
                                            updateActionButtonsWithMessageId(assistantMessageElement, meta.id);
                                        }
                                    
                                    } else if (parsedData.type === 'done') {
                                        // Stream finished successfully
                                        console.log("Stream finished event received.");
                                        
                                        // Ensure the final response text is added to JS history
                                        if (responseText && (!messageHistory.length || messageHistory[messageHistory.length - 1]?.role !== 'assistant')) {
                                             // Add only if history is empty or last message wasn't assistant's
                                             // This prevents duplicates if content was added earlier
                                            messageHistory.push({
                                                role: 'assistant',
                                                content: responseText 
                                            });
                                            console.log("Added final assistant response to JS history.");
                                        } else if (responseText && messageHistory.length > 0 && messageHistory[messageHistory.length - 1]?.role === 'assistant') {
                                            // Update the last history entry's content if needed (less likely needed now)
                                            // messageHistory[messageHistory.length - 1].content = responseText;
                                        }
                                        
                                        // Re-enable input, etc. 
                                        // messageInput.disabled = false;
                                        // sendButton.disabled = false;
                                        
                                        return; // Exit the processing loop
                                    }
                                    
                                } catch (error) {
                                    console.error('Error parsing SSE data JSON:', error, data);
                                    // messageContent.innerHTML = `<span class="error">Error processing response data.</span>`;
                                    // return; // Stop processing on parsing error
                                }
                            } else {
                                // Handle lines that don't start with 'data: ' if necessary (e.g., comments)
                                // console.log("Received non-data line:", message); 
                            }
                        } // End of loop processing complete messages
                        
                        // Continue reading from the stream
                        return processChunks();
                    }); // End of reader.read().then()
                } // End of processChunks function definition

                // Helper function (ensure this is defined or integrated)
                function updateActionButtonsWithMessageId(messageElement, messageId) {
                    // Ensure messageElement is valid
                    if (!messageElement) return; 
                    
                    const upvoteBtn = messageElement.querySelector('.upvote-btn');
                    const downvoteBtn = messageElement.querySelector('.downvote-btn');
                    const copyBtn = messageElement.querySelector('.copy-btn');

                    // Check if buttons exist before setting dataset properties
                    if (upvoteBtn) upvoteBtn.dataset.messageId = messageId;
                    if (downvoteBtn) downvoteBtn.dataset.messageId = messageId;
                    if (copyBtn) copyBtn.dataset.messageId = messageId; 
                    
                    // If using delegated listeners, no need to re-attach handlers.
                    // If attaching directly in addMessage, ensure they are attached
                    // after the message ID is set.
                }


                // Start the stream processing
                return processChunks();
// === END OF REPLACEMENT CODE FOR STREAM PROCESSING LOGIC ===
Check addMessage Function: Ensure your addMessage function correctly creates the placeholder .message-metadata div (initially empty) for assistant messages, and the .message-actions div. The code provided in the previous script.js seemed to do this, but verify it exists.
Check formatModelName: Ensure this function exists and works as intended.
Check Event Listeners: Ensure the event listeners for copy/share/vote buttons are attached correctly (preferably using event delegation on the chatMessages container rather than attaching to each button individually) so they work even for buttons added dynamically and updated after the metadata arrives.
3. Verify models.py:

No changes should be needed based on the provided models.py, as the necessary fields (share_id, rating, model_id_used, prompt_tokens, completion_tokens) already exist.
Apply these code replacements and updates. Remember to restart your Flask application after modifying app.py. 